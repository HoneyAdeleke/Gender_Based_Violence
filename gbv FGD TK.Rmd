---
title: "FGD TK"
author: "Honey A. Adeleke"
date: "`r Sys.Date()`"
output: html_document
---


## Loading Libraries

```{r packages}
library(readr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(tm)
library(syuzhet)
library(dplyr)
library(topicmodels)
library(broom)
library(tidyverse)
library(readxl)
```

```{r Importing_Data, echo=T}
gbv_FGDTK<- read_excel("Gender Based Violence.xlsx", sheet = "FGD Teacher Kebbi")
str(gbv_FGDTK)
```

```{r Building_Corpus, echo=T}
corpus = iconv(gbv_FGDTK$Responses, to=  "UTF-8")
corpus1 = Corpus(VectorSource(corpus))
inspect(corpus1[1:10])
```


```{r Cleaning_the_text, echo=T, warning=FALSE}
corpus2=tm_map(corpus1, tolower) # To make bring document to lower case
corpus3=tm_map(corpus2, removePunctuation) # To remove punctuation
corpus4=tm_map(corpus3, removeNumbers) # remove number
cleanset=tm_map(corpus4, removeWords, stopwords('english')) # To remove English words that are common and will not add much values
cleanset1=tm_map(cleanset, stripWhitespace) #To get rid of the extra spaces
inspect(cleanset1[1:10])
```


```{r TDM, echo=T}
gbv_FGDTK_tdm<-TermDocumentMatrix(cleanset1)
gbv_FGDTK_tdm1 = as.matrix(gbv_FGDTK_tdm)
```


```{r Bar_plot, echo=T}
gbv_FGDTK_bar=rowSums(gbv_FGDTK_tdm1) #To find how often each row appears
gbv_FGDTK_bar1=subset(gbv_FGDTK_bar,gbv_FGDTK_bar>=20) #words with frequency greater than or equal to 5 will appear
barplot(gbv_FGDTK_bar1,
        las =2,
        col = rainbow(7))
```

```{r Word_cloud, echo=T}
gbv_FGDTK_bar2<- sort(rowSums(gbv_FGDTK_tdm1), decreasing = T)
wordcloud(words = names(gbv_FGDTK_bar2),
          freq = gbv_FGDTK_bar2,
          max.words = 1000,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(7,"Dark2"),
          scale = c(2,0.1),
          rot.per = 0.3)
```

```{r Word_cloud2, echo=T}
library(wordcloud2)
gbv_FGDTK_bar3<-data.frame(names(gbv_FGDTK_bar2),gbv_FGDTK_bar2)
colnames(gbv_FGDTK_bar3)<-c("word", "freq")
wordcloud2(gbv_FGDTK_bar3,
           size=0.2,
           shape="circle")

wordcloud2(gbv_FGDTK_bar3,
           size=0.15,
           shape="star",
           rotateRatio = 0.4,
           minSize = 1)
```

```{r Sentiment_Analysis, echo=T}
# Read file
gbv_FGDTK_sentiment <- get_nrc_sentiment(corpus)
write.csv(gbv_FGDTK_sentiment, "gbv_FGDTK_sentiment.csv")
head(gbv_FGDTK_sentiment)
```

```{r Barplot2}
barplot(colSums(gbv_FGDTK_sentiment),
        las = 2,
        col = rainbow(10),
        ylab = "Frequency",
        main = "sentiments of the gbv_FGDTK")
```


```{r Topic Modelling, echo=TRUE}
gbv_FGDTK_dtm <- DocumentTermMatrix(Corpus(VectorSource(cleanset)))
gbv_FGDTK_lda_model <- LDA(gbv_FGDTK_dtm, k = 5, control = list(seed = 1234))
gbv_FGDTK_topics <- tidy(gbv_FGDTK_lda_model, matrix = "beta")
top_terms <- gbv_FGDTK_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  ggplot(aes(x = reorder_within(term, beta, topic), y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top Terms in Each Topic", x = "Term", y = "Beta")
```