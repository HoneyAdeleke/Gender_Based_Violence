---
title: "FGD Student Lagos"
author: "Honey A. Adeleke"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---


## Loading Libraries

```{r packages}
library(readr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(tm)
library(syuzhet)
library(dplyr)
library(topicmodels)
library(broom)
library(tidyverse)
library(readxl)
```

```{r Importing_Data, echo=T}
gbv_FGDSL<- read_excel("Gender Based Violence.xlsx", sheet = "FGD Student Lagos")
str(gbv_FGDSL)
```

```{r Building_Corpus, echo=T}
corpus = iconv(gbv_FGDSL$Responses, to= "UTF-8")
corpus1 = Corpus(VectorSource(corpus))
inspect(corpus1[1:10])
```


```{r Cleaning_the_text, echo=T, warning=FALSE}
corpus1 <- tm_map(corpus1, stemDocument)  # Stemming the text
corpus2=tm_map(corpus1, tolower) # To make bring document to lower case
corpus3=tm_map(corpus2, removePunctuation) # To remove punctuation
corpus4=tm_map(corpus3, removeNumbers) # remove number
cleanset=tm_map(corpus4, removeWords, stopwords('english')) # To remove English words that are common and will not add much values
cleanset1=tm_map(cleanset, stripWhitespace) #To get rid of the extra spaces
inspect(cleanset1[1:10])
```


```{r TDM, echo=T}
gbv_FGDSL_tdm<-TermDocumentMatrix(cleanset1)
gbv_FGDSL_tdm1 = as.matrix(gbv_FGDSL_tdm)
```


```{r Bar_plot, echo=T}
gbv_FGDSL_bar=rowSums(gbv_FGDSL_tdm1) #To find how often each row appears
gbv_FGDSL_bar1=subset(gbv_FGDSL_bar,gbv_FGDSL_bar>=10) #words with frequency greater than or equal to 10 will appear
barplot(gbv_FGDSL_bar1,
        las =2,
        col = rainbow(7),
         main= "Frequency of words that appears more than 10 times")
```

```{r Word_cloud, echo=T}
gbv_FGDSL_bar2<- sort(rowSums(gbv_FGDSL_tdm1), decreasing = T)
wordcloud(words = names(gbv_FGDSL_bar2),
          freq = gbv_FGDSL_bar2,
          max.words = 1000,
          random.order = F,
          min.freq = 2,
          colors = brewer.pal(7,"Dark2"),
          scale = c(2,0.5),
          rot.per = 0.3)
```

```{r Word_cloud2, echo=T}
library(wordcloud2)
gbv_FGDSL_bar3<-data.frame(names(gbv_FGDSL_bar2),gbv_FGDSL_bar2)
colnames(gbv_FGDSL_bar3)<-c("word", "freq")
wordcloud2(gbv_FGDSL_bar3,
           size=0.8,
           shape="circle",
           rotateRatio = 0.4,
           minSize = 1)
```

```{r Sentiment_Analysis, echo=T}
# Read file
gbv_FGDSL_sentiment <- get_nrc_sentiment(corpus)
write.csv(gbv_FGDSL_sentiment, "gbv_FGDSL_sentiment.csv")
head(gbv_FGDSL_sentiment)
```

```{r Barplot2}
barplot(colSums(gbv_FGDSL_sentiment),
        las = 2,
        col = rainbow(10),
        ylab = "Frequency",
        main = "Sentiments of the Focus Group discussion among students in Lagos")
```


```{r Topic Modelling, echo=TRUE}
gbv_FGDSL_dtm <- DocumentTermMatrix(Corpus(VectorSource(cleanset)))
gbv_FGDSL_lda_model <- LDA(gbv_FGDSL_dtm, k = 5, control = list(seed = 1234))
gbv_FGDSL_topics <- tidy(gbv_FGDSL_lda_model, matrix = "beta")
top_terms <- gbv_FGDSL_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  ggplot(aes(x = reorder_within(term, beta, topic), y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top Terms in Each Topic", x = "Term", y = "Beta")
```